import cv2                                     # OpenCV para captura de vídeo y procesamiento de imagen  
import threading                                # para captura en paralelo  
import time                                     # para timestamps y pausas  
import numpy as np                              # para manipulación de arrays  
from tracker import CentroidTracker                   # biblioteca SORT importada (ajusta nombre si distinto)  

# --- Configuración inicial ---
MIN_AREA_PEATON = 2000                          # área mínima en pixeles para considerar un “objeto significativo” (peatón)  
MIN_AREA_VEHICULO = 8000                        # área mínima para considerar vehículo  
FRAME_WIDTH = 640                                # ancho de los frames que capturamos  
FRAME_HEIGHT = 480                               # alto de los frames  
DISPLAY = True                                   # si queremos ver ventana de preview (en producción puede False)  

class CameraStream:  
    def __init__(self, src, name="Cam"):  
        self.src = src                             # índice o ruta de la cámara  
        self.name = name                           # nombre identificador para logging  
        self.cap = cv2.VideoCapture(src)           # inicializa la captura  
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, FRAME_WIDTH)  
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, FRAME_HEIGHT)  
        self.ret = False                            # flag de captura válida  
        self.frame = None                           # última imagen leída  
        self.stopped = False                        # flag de parada del hilo  
        self.bs = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=16, detectShadows=True)  
        self.lock = threading.Lock()                # lock para proteger acceso a frame compartido  
        self.thread = threading.Thread(target=self.update, args=())  
        self.thread.daemon = True                   # hacer hilo demonio para cerrar junto con main  
        self.thread.start()                         

    def update(self):  
        while not self.stopped:  
            ret, frame = self.cap.read()              # capturar nuevo frame  
            if not ret:  
                print(f"[{self.name}] captura fallida")  
                self.stop()  
                return  
            with self.lock:  
                self.ret = ret  
                self.frame = frame.copy()             # copiar frame para seguridad  
        self.cap.release()  

    def read(self):  
        with self.lock:  
            if self.frame is None:  
                return False, None  
            return self.ret, self.frame.copy()        # devolver copia para no bloquear  

    def stop(self):  
        self.stopped = True  
        self.thread.join()                           # espera a que el hilo termine  

def detect_and_classify(frame, bg_subtractor):  
    """
    Detección + clasificación heurística (vehículo vs peatón) basada en tamaño del contorno.
    Retorna lista de (x,y,w,h, clase) con clase en {"pedestrian","vehicle"}.
    """
    fg = bg_subtractor.apply(frame)                 # aplicar sustracción de fondo  
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))  
    fg = cv2.morphologyEx(fg, cv2.MORPH_OPEN, kernel, iterations=2)  
    contours, _ = cv2.findContours(fg, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  
    detections = []  
    for cnt in contours:  
        area = cv2.contourArea(cnt)  
        if area < MIN_AREA_PEATON:                  # si área muy pequeña, ignorar  
            continue  
        x, y, w, h = cv2.boundingRect(cnt)  
        if area >= MIN_AREA_VEHICULO:  
            cls = "vehicle"  
        else:  
            cls = "pedestrian"  
        detections.append((x, y, w, h, cls))  
    return detections  

def main():  
    cam0 = CameraStream(0, name="Cam0")            # cámara 0  
    cam1 = CameraStream(1, name="Cam1")            # cámara 1  
    tracker0 = sort.SORT()                          # tracker para cámara 0  
    tracker1 = sort.SORT()                          # tracker para cámara 1  
    try:  
        while True:  
            t0 = time.time()                        # timestamp inicio ciclo  
            ret0, frame0 = cam0.read()              # leer cámara 0  
            ret1, frame1 = cam1.read()              # leer cámara 1  
            if not (ret0 and ret1):  
                print("Una de las cámaras no devuelve frames. Saliendo.")  
                break  
            dets0 = detect_and_classify(frame0, cam0.bs)  
            dets1 = detect_and_classify(frame1, cam1.bs)  
            # Convertir detecciones a formato del tracker: [xmin, ymin, xmax, ymax, score]  
            dets0_np = np.array([[x, y, x+w, y+h, 1.0] for (x,y,w,h,cls) in dets0])  
            dets1_np = np.array([[x, y, x+w, y+h, 1.0] for (x,y,w,h,cls) in dets1])  
            tracks0 = tracker0.update(dets0_np)     # actualizar tracker cámara 0  
            tracks1 = tracker1.update(dets1_np)     # actualizar tracker cámara 1  
            # Dibujar resultados y loggeo  
            for track in tracks0:  
                x1, y1, x2, y2, track_id = track.astype(int)  
                cv2.rectangle(frame0, (x1,y1), (x2,y2), (0,255,0), 2)  
                cv2.putText(frame0, f"ID {track_id}", (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)  
            for track in tracks1:  
                x1, y1, x2, y2, track_id = track.astype(int)  
                cv2.rectangle(frame1, (x1,y1), (x2,y2), (255,0,0), 2)  
                cv2.putText(frame1, f"ID {track_id}", (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 2)  
            timestamp = time.time()  
            print(f"{timestamp:.2f} | Cam0 num_tracks: {len(tracks0)} | Cam1 num_tracks: {len(tracks1)}")  
            if DISPLAY:  
                cv2.imshow("Cam0", frame0)  
                cv2.imshow("Cam1", frame1)  
                if cv2.waitKey(1) & 0xFF == ord('q'):  
                    break  
            # calcular fps aproximada  
            elapsed = time.time() - t0  
            # opcional: print(f"Loop time: {elapsed:.3f}s → FPS {1/elapsed:.1f}")  
    except KeyboardInterrupt:  
        print("Interrumpido por usuario")  
    finally:  
        cam0.stop()  
        cam1.stop()  
        cv2.destroyAllWindows()  

if __name__ == "__main__":  
    main()  
