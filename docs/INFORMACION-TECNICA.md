Documento creado por la integrante Kendy Arias Ortiz con rol de l√≠der t√©cnico.

#La informaci√≥n t√©cnica explica los puntos 6,7,8 y 9 de la entrega preliminar.

# 6. Vista Funcional del Sistema: Descomposici√≥n de Funciones

El sistema **Cruces Inteligentes con Edge AI** se descompone en m√≥dulos funcionales esenciales para cumplir con los requerimientos establecidos anteriormente. Esta vista describe las capacidades del sistema, bas√°ndose en la necesidad de captura, procesamiento y clasificaci√≥n de objetos en cruces concurridos, adem√°s de los m√≥dulos para el control del sem√°foro del cruce.

### I. Captura y Preprocesamiento de Video
Este m√≥dulo se encarga de adquirir el flujo de video en tiempo real desde las c√°maras conectadas al Raspberry Pi. Los frames obtenidos se preprocesan para optimizar el rendimiento del modelo de IA mediante t√©cnicas como redimensionamiento, filtrado y normalizaci√≥n. Adem√°s, se segmenta el entorno del cruce para diferenciar v√≠as vehiculares, pasos peatonales y zonas de fauna, facilitando la clasificaci√≥n contextual de los objetos detectados.

### II. Procesamiento e Inferencia con IA
Aqu√≠ se ejecutan los modelos de aprendizaje autom√°tico sobre los frames preprocesados. El sistema detecta y clasifica en tiempo real veh√≠culos, peatones y fauna, analizando su movimiento para estimar direcci√≥n y velocidad. Con esta informaci√≥n, el m√≥dulo toma decisiones locales sobre el estado del cruce, como activar o no el paso peatonal, priorizando la seguridad y la fluidez del tr√°nsito.

### III. Control del Cruce Inteligente
Este m√≥dulo traduce las decisiones de la IA en acciones concretas sobre el sem√°foro. En funci√≥n del an√°lisis del entorno, activa o desactiva las luces (rojo, verde) en la simulaci√≥n. La visualizaci√≥n del sem√°foro puede implementarse en Python utilizando bibliotecas como OpenCV, Tkinter o Pygame, permitiendo mostrar de manera gr√°fica el estado de las se√±ales. Adem√°s, este m√≥dulo gestiona prioridades de paso seg√∫n la densidad de tr√°fico y supervisa que los actuadores respondan correctamente, aunque el sem√°foro sea virtual.

### IV. Sistema Embebido y Software Base
Se encarga de la administraci√≥n del entorno de ejecuci√≥n sobre la Raspberry Pi. Incluye la construcci√≥n de la imagen de Linux embebido con Yocto Project, integrando las dependencias necesarias (OpenCV, TensorFlow Lite). Adem√°s, gestiona los recursos del sistema y asegura la inicializaci√≥n autom√°tica y el monitoreo constante del servicio principal que mantiene funcionando todo el sistema.

### V. Registro y Monitoreo del Sistema
Este m√≥dulo documenta la operaci√≥n del sistema para su validaci√≥n y depuraci√≥n. Registra eventos importantes, como detecciones y decisiones, permite la visualizaci√≥n del estado del cruce mediante una interfaz local o remota, y facilita la exportaci√≥n de datos a una red de monitoreo o almacenamiento local para an√°lisis posterior.


| M√≥dulo Funcional | Descripci√≥n General | Funciones Espec√≠ficas Requeridas |
|-----------------|------------------|--------------------------------|
| I. Captura y Preprocesamiento de Video | Control del flujo de video proveniente de la c√°mara conectada al Raspberry Pi, preparando las im√°genes para an√°lisis de IA. | 1. Captura de video en tiempo real. 2. Preprocesamiento (redimensionar, filtrar, normalizar). 3. Segmentaci√≥n del entorno (calles, pasos peatonales, zonas de fauna). |
| II. Procesamiento e Inferencia con IA | Uso de modelos de aprendizaje autom√°tico (TensorFlow Lite + OpenCV) para detectar entidades relevantes. | 1. Detecci√≥n y clasificaci√≥n de veh√≠culos, peatones y fauna. 2. An√°lisis de movimiento (direcci√≥n y velocidad). 3. Toma de decisiones local para paso peatonal. |
| III. Control del Cruce Inteligente | Gestiona se√±ales del sem√°foro seg√∫n el procesamiento de IA. | 1. Activaci√≥n de se√±ales (rojo/verde). 2. Gesti√≥n de prioridades seg√∫n densidad de tr√°fico. 3. Supervisi√≥n del estado de los actuadores. |
| IV. Sistema Embebido y Software Base | Administraci√≥n del entorno de ejecuci√≥n sobre Raspberry Pi, integraci√≥n del SO embebido, bibliotecas y servicios. | 1. Integraci√≥n Yocto Project (OpenCV, TensorFlow Lite, GPIO). 2. Gesti√≥n de recursos (CPU, memoria, sensores). 3. Inicializaci√≥n y monitoreo del servicio principal. |
| V. Registro y Monitoreo del Sistema | Registro de eventos y resultados para validaci√≥n y depuraci√≥n. | 1. Registro de actividad (detecciones, decisiones). 2. Interfaz de diagn√≥stico local o remota. 3. Exportaci√≥n de datos a red o almacenamiento local. |                                 |


# 7. Arquitectura del Sistema Propuesto (Hardware y Software)

La arquitectura define la estructura f√≠sica y l√≥gica del nodo de monitoreo, implementando un esquema de **Edge Computing** donde el procesamiento ocurre en el dispositivo, no en la nube.  
El nodo procesa video en tiempo real para la detecci√≥n de peatones, veh√≠culos y fauna, y controla un sem√°foro virtual mostrando el flujo del cruce en una pantalla conectada al sistema.

---

## Arquitectura de Hardware üíæ

El nodo se basa en una plataforma de bajo costo y alta flexibilidad:

- **Plataforma de C√≥mputo Embebido:** Raspberry Pi 4 Model B (4GB RAM), adecuada para procesamiento de video en tiempo real y ejecuci√≥n de modelos TensorFlow Lite.  
- **Perif√©ricos de Entrada (Visi√≥n):** Dos c√°maras USB conectadas a la Raspberry Pi, encargadas de capturar video de alta resoluci√≥n de diferentes √°ngulos del cruce. Se usan puertos USB 3.0 para asegurar ancho de banda suficiente.  
- **Perif√©rico de Salida (Visualizaci√≥n):** Pantalla HDMI conectada a la Raspberry Pi para mostrar el flujo de video en tiempo real, el estado del sem√°foro virtual y m√©tricas relevantes.  
- **Almacenamiento:** Tarjeta MicroSD Kingston Canvas Select Plus de 32GB, suficiente para almacenar el sistema operativo, modelos de IA y datos temporales de prueba.  
- **Conectividad:** M√≥dulo Ethernet/WiFi integrado para la comunicaci√≥n de m√©tricas y gesti√≥n remota del nodo dentro de la red de monitoreo.

---

## Arquitectura de Software üíª

La estructura de software se organiza en cuatro capas principales:

### 1. Capa de Aplicaci√≥n (Edge AI)
Contiene la l√≥gica principal del sistema:

- **Algoritmo de Monitoreo:** C√≥digo que orquesta la captura, detecci√≥n, clasificaci√≥n y tracking de objetos en tiempo real desde las c√°maras.  
- **Modelos de ML:** Archivos optimizados (`.tflite`) que ejecutan la inferencia directamente en la Raspberry Pi.

### 2. Capa de Control del Sem√°foro y Visualizaci√≥n
M√≥dulo encargado de traducir las decisiones de la IA en acciones sobre el sem√°foro y mostrar la informaci√≥n en la pantalla:

- **Simulaci√≥n de Sem√°foro:** Visualizaci√≥n del estado de las se√±ales (rojo/amarillo/verde) utilizando Python con bibliotecas como OpenCV, Tkinter o Pygame.  
- **Gesti√≥n de Prioridades:** Ajuste de tiempos de cambio de luz seg√∫n la densidad de tr√°fico y presencia de peatones.  
- **Visualizaci√≥n en Pantalla:** Muestra el flujo de video en tiempo real, el sem√°foro virtual y m√©tricas importantes para supervisi√≥n.  
- **Supervisi√≥n de Actuadores:** Asegura que los cambios de estado se apliquen correctamente.

### 3. Capa de Middleware (Librer√≠as)
Proporciona las herramientas necesarias para la ejecuci√≥n en el target:

- **TensorFlow Lite:** Runtime eficiente para la ejecuci√≥n de modelos de IA en la Raspberry Pi.  
- **OpenCV:** Librer√≠a de Visi√≥n por Computador para preprocesamiento de frames, segmentaci√≥n de zonas del cruce y utilidades de imagen.

### 4. Capa de Sistema Operativo
La base del sistema:

- **Linux Embebido:** Imagen m√≠nima optimizada para Raspberry Pi 4, generada mediante Yocto Project.  
- **Kernel Linux:** N√∫cleo configurado para optimizar el rendimiento, la gesti√≥n de perif√©ricos y la comunicaci√≥n con c√°maras USB.


# 8. Dependencias de Software y 9. Estrategia de Integraci√≥n

---

## Dependencias de Software üì¶

Las dependencias son importantes para el desarrollo de la imagen con **Yocto Project**, ya que deben incluirse como recetas en el build system.

| Dependencia | Tipo | Prop√≥sito |
|-------------|------|-----------|
| **TensorFlow Lite (TFLite)** | Runtime de ML | Ejecuci√≥n de modelos de detecci√≥n y clasificaci√≥n en el Edge. |
| **OpenCV** | Librer√≠a de Visi√≥n | Manipulaci√≥n de video, preprocesamiento de im√°genes para el modelo de ML. |
| **Python 3** | Int√©rprete/Librer√≠as | Lenguaje base para el desarrollo del c√≥digo de la aplicaci√≥n (si aplica). |
| **Drivers de C√°mara (V4L2)** | Kernel/Drivers | Interfaz para la comunicaci√≥n con el m√≥dulo de c√°mara de la Raspberry Pi. |

---

## 9. Estrategia de Integraci√≥n (Yocto Project) üõ†Ô∏è

La estrategia de integraci√≥n asegura que la aplicaci√≥n de **Edge AI** corra de manera robusta sobre un sistema operativo optimizado y personalizado para la **Raspberry Pi 4 Model B**. Se busca empaquetar todo en una **imagen √∫nica**, lista para deploy y ejecuci√≥n en el nodo de monitoreo.

---

### 1. Identificaci√≥n de Recetas
- Analizar las dependencias necesarias para el proyecto, incluyendo:
  - **TensorFlow Lite** (`tflite`) para la inferencia de modelos de IA.
  - **OpenCV** para procesamiento de video y segmentaci√≥n de zonas del cruce.
  - Librer√≠as adicionales como **numpy**, **libjpeg**, **zlib**, etc.
- Identificar o sintetizar las recetas (`.bb files`) que permitan compilar estas dependencias para la arquitectura ARM de la Raspberry Pi.

### 2. Generaci√≥n de Imagen Base
- Configurar Yocto Project para el target **Raspberry Pi 4 B**.
- Generar una imagen m√≠nima de Linux embebido, con soporte para:
  - CPU, GPU y aceleraci√≥n de hardware.
  - USB 3.0 para las c√°maras.
  - HDMI para la pantalla.
  - WiFi/Ethernet para conectividad.
- Esta imagen servir√° como base para integrar todas las dependencias y la aplicaci√≥n.

### 3. Inclusi√≥n de Dependencias
- Modificar la receta de la imagen final para incluir las librer√≠as y frameworks identificados.
- Asegurar que **TensorFlow Lite**, **OpenCV** y sus dependencias se compilen correctamente para la arquitectura ARM de la Raspberry Pi.
- Realizar pruebas de compilaci√≥n cruzada y verificaci√≥n de compatibilidad.

### 4. Integraci√≥n de la Aplicaci√≥n Principal
- Crear la receta para la aplicaci√≥n de monitoreo del cruce inteligente.
- Configurar la aplicaci√≥n para que:
  - Se ejecute autom√°ticamente al iniciar el sistema operativo.
  - Capture y procese video de las c√°maras USB.
  - Controle y visualice el sem√°foro virtual en la pantalla HDMI.
  - Env√≠e m√©tricas a la red de monitoreo v√≠a WiFi/Ethernet.

### 5. S√≠ntesis de Imagen Final
- Ejecutar `bitbake` para compilar la imagen final, que contendr√°:
  - Linux embebido optimizado para Raspberry Pi 4 B.
  - Todas las librer√≠as y dependencias (TensorFlow Lite, OpenCV, etc.).
  - La aplicaci√≥n de Edge AI lista para correr autom√°ticamente.
- Validar que la imagen generada sea funcional y estable.

### 6. Despliegue y Verificaci√≥n
- Instalar la imagen final en la Raspberry Pi utilizando la tarjeta MicroSD.
- Conectar las c√°maras USB, la pantalla HDMI y verificar la operaci√≥n completa del nodo:
  - Captura de video y procesamiento en tiempo real.
  - Visualizaci√≥n del sem√°foro virtual.
  - Registro de eventos y m√©tricas enviadas a la red de monitoreo.

---

**Notas adicionales:**  
- A√∫n en desarrollo: se agregar√°n im√°genes de la arquitectura y conexiones f√≠sicas.  
- Se ampliar√° la especificaci√≥n de hardware incluyendo **pantalla, c√°maras, microSD y conectividad**, para documentar completamente el nodo de monitoreo.

