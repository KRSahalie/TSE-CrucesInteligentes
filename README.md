# üö¶ Proyecto 2 ‚Äì Cruces Inteligentes con Edge AI  

[![Estado](https://img.shields.io/badge/estado-en_desarrollo-blue.svg)]()
[![Plataforma](https://img.shields.io/badge/target-Raspberry%20Pi-green.svg)]()
[![Build](https://img.shields.io/badge/build-Yocto-kirkstone.svg)]()
[![Lenguajes](https://img.shields.io/badge/lenguajes-Python-orange.svg)]()
[![Stack](https://img.shields.io/badge/stack-OpenCV%20%7C%20TensorFlow%20Lite%20%7C%20V4L2%20%7C%20systemd-lightgrey.svg)]()

## Tabla de Contenido
- [1. Introducci√≥n](#1-introducci√≥n)
- [2. Justificaci√≥n](#2-justificaci√≥n)
- [3. Requerimientos](#3-requerimientos)
  - [3.1 Requerimientos funcionales (RF)](#31-requerimientos-funcionales-rf)
  - [3.2 Requerimientos no funcionales (RNF)](#32-requerimientos-no-funcionales-rnf)
  - [3.3 Interfaces y dependencias](#33-interfaces-y-dependencias)
  - [3.4 Criterios de aceptaci√≥n](#34-criterios-de-aceptaci√≥n)
- [4. Casos de uso](#4-casos-de-uso)
- [5. Arquitectura del sistema](#5-arquitectura-del-sistema)
- [6. Vista operacional y funcional](#6-vista-operacional-y-funcional)
- [7. Plan de trabajo y cronograma](#7-plan-de-trabajo-y-cronograma)
- [8. Integraci√≥n y despliegue (Yocto)](#8-integraci√≥n-y-despliegue-yocto)
- [9. Pruebas y validaci√≥n](#9-pruebas-y-validaci√≥n)
- [10. M√©tricas y observabilidad](#10-m√©tricas-y-observabilidad)
- [11. Bit√°cora Christopher](#11-bitacora-christopher)
- [12. Bit√°cora Elena](#12-bitacora-elena)
- [13. Bit√°cora Kendy](#13-bitacora-kendy)
- [14. Documentaci√≥n Entrega Preliminar](#14--documentaci√≥n-entrega-preliminar)


---

## üìò Descripci√≥n del Proyect 
El proyecto tiene como objetivo dise√±ar e implementar un sistema de **cruce inteligente** que utilice **Edge AI** (inteligencia artificial en el borde) para detectar veh√≠culos, peatones o fauna, y optimizar el flujo del tr√°fico de forma aut√≥noma.  
El sistema estar√° basado en **Raspberry Pi**, integrando **TensorFlow Lite** y **OpenCV**, dentro de una imagen Linux personalizada generada con **Yocto Project**.
=======

## 1. Introducci√≥n  
<p align="justify">
El aumento constante del parque vehicular y la expansi√≥n de las ciudades han generado una problem√°tica creciente en la gesti√≥n del tr√°nsito y la seguridad vial. En los cruces m√°s concurridos, donde convergen peatones, ciclistas, motocicletas y veh√≠culos particulares, los accidentes y la congesti√≥n se presentan con mayor frecuencia debido a la limitada capacidad de los sistemas tradicionales para adaptarse a las condiciones din√°micas del entorno urbano.
</p>
<p align="justify">
En este contexto, la inteligencia artificial embebida (Edge AI) surge como una alternativa tecnol√≥gica capaz de ejecutar algoritmos de visi√≥n por computador y aprendizaje autom√°tico directamente en dispositivos de bajo consumo energ√©tico, como el Raspberry Pi. Esta capacidad de procesamiento local permite realizar tareas de detecci√≥n, clasificaci√≥n y seguimiento de objetos en tiempo real sin depender completamente de la conectividad a la nube, lo que reduce la latencia y mejora la privacidad de los datos.
</p>
<p align="justify">
El presente proyecto propone el desarrollo de un sistema embebido que funcione como nodo inteligente dentro de una red de monitoreo de tr√°nsito urbano. Cada nodo estar√° basado en hardware de Raspberry Pi con una c√°mara perif√©rica y sensores complementarios, ejecutando modelos optimizados de visi√≥n artificial con TensorFlow Lite y OpenCV. El objetivo es detectar y clasificar peatones, ciclistas, fauna o veh√≠culos, y con ello ofrecer informaci√≥n √∫til para la toma de decisiones en la gesti√≥n del tr√°nsito y el mejoramiento de la seguridad vial.
</p>
<p align="justify">
El desarrollo de este tipo de sistemas no solo promueve la aplicaci√≥n pr√°ctica de los conocimientos adquiridos en la asignatura de Sistemas Embebidos, sino que tambi√©n alinea la formaci√≥n del estudiantado con las tendencias actuales de la industria electr√≥nica, donde convergen la inteligencia artificial, el IoT y la computaci√≥n de borde.
</p>


## 2. Justificaci√≥n
<p align="justify">
Las intersecciones urbanas concentran buena parte de las fricciones de la movilidad: trayectorias impredecibles de peatones y ciclistas, picos de congesti√≥n y decisiones de conducci√≥n tomadas bajo presi√≥n. En este entorno cambiante, los esquemas tradicionales de control ‚Äîbasados en temporizaciones fijas o conteos manuales‚Äî resultan insuficientes para anticipar comportamientos y reaccionar con la rapidez que exige la seguridad vial. Incorporar inteligencia en el borde (Edge AI) permite llevar el an√°lisis al lugar donde ocurre el fen√≥meno, reduciendo la latencia, disminuyendo la dependencia de la nube y resguardando la privacidad de quienes transitan.
</p>

<p align="justify">
Este proyecto propone nodos embebidos basados en Raspberry Pi que ejecutan, en tiempo real, modelos livianos de visi√≥n por computador para detectar, clasificar y seguir peatones, ciclistas, fauna y veh√≠culos. Al observar el flujo local con granularidad fina (escena a escena), el sistema puede proveer evidencia cuantitativa para ajustar fases semaf√≥ricas, activar alertas preventivas o caracterizar riesgos espec√≠ficos del cruce (por ejemplo, puntos ciegos peatonales en determinadas horas). As√≠, la soluci√≥n trasciende el conteo b√°sico y se orienta a decisiones operativas informadas que impactan directamente en la reducci√≥n de incidentes y la mejora de la fluidez.
</p>

<p align="justify">
Desde la perspectiva tecnol√≥gica, la iniciativa articula un ecosistema embebido moderno: construcci√≥n de una imagen de Linux con Yocto Project, integraci√≥n de OpenCV y TensorFlow Lite, y despliegue en hardware accesible. Esta combinaci√≥n habilita ciclos de iteraci√≥n cortos (medici√≥n‚Äìajuste‚Äìvalidaci√≥n) y una escalabilidad pragm√°tica, pues es factible replicar nodos en m√∫ltiples cruces con costos razonables y mantenimiento estandarizado.
</p>

<p align="justify">
El proyecto tambi√©n posee un alto valor formativo, al poner al equipo frente a retos reales de ingenier√≠a: levantamiento y priorizaci√≥n de requerimientos, dise√±o de arquitecturas de hardware y software, manejo de dependencias, pruebas en campo y validaci√≥n contra casos de uso. As√≠, el estudiantado fortalece competencias clave ‚Äîdise√±o, integraci√≥n, validaci√≥n y documentaci√≥n‚Äî alineadas con las demandas actuales de la industria electr√≥nica y de sistemas embebidos.
</p>


En s√≠ntesis, la propuesta es pertinente por cuatro razones:

* Relevancia social: contribuye a la seguridad vial y a la movilidad sostenible en puntos cr√≠ticos de la ciudad.

* Eficiencia operativa: habilita decisiones locales de baja latencia que mejoran el desempe√±o del cruce.

* Sostenibilidad tecnol√≥gica: se apoya en hardware de bajo costo y software modular, replicable y mantenible.

* Formaci√≥n integral: consolida competencias profesionales con una experiencia aplicada de extremo a extremo.

Con base en lo anterior, en la siguiente secci√≥n se detallan los requerimientos funcionales y no funcionales que orientan el dise√±o y desarrollo del sistema propuesto.

## 3. Requerimientos

### 3.1 Requerimientos funcionales (RF)
- **RF1.** Capturar video en tiempo real desde c√°mara (CSI/USB, V4L2).
- **RF2.** Detectar y **clasificar** veh√≠culos, peatones y fauna (TensorFlow Lite).
- **RF3.** **Seguimiento (tracking)** de objetos con IDs temporales.
- **RF4.** **Eventos** por cruce (conteos por clase, timestamps) y agregados (p.ej., por minuto).
- **RF5.** Exponer m√©tricas localmente (CLI/log) y **publicar** a red (HTTP/MQTT).
- **RF6.** **Arranque aut√≥nomo**: service de la app al boot (systemd).
- **RF7.** **Registro de auditor√≠a**: fallos, latencias, FPS y salud del nodo.

### 3.2 Requerimientos no funcionales (RNF)
- **RNF1.** Latencia ‚Äúcaptura‚Üídetecci√≥n‚Üíevento‚Äù ‚â§ **500 ms** (meta demo).
- **RNF2.** Throughput objetivo ‚â• **10 FPS** sostenidos a **640√ó480**.
- **RNF3.** Robustez: recuperaci√≥n si la c√°mara se desconecta/reconecta sin reiniciar.
- **RNF4.** **Observabilidad**: logs con niveles y m√©tricas (CPU/RAM/FPS/colas).
- **RNF5.** **Despliegue reproducible** con **Yocto** (OpenCV, TFLite, drivers incluidos).
- **RNF6.** **Seguridad m√≠nima**: no exponer servicios sin autenticaci√≥n fuera de la LAN del demo.
- **RNF7.** **Mantenibilidad**: c√≥digo/recetas en GitHub con README de build/instalaci√≥n.

### 3.3 Interfaces y dependencias
- **I1.** C√°mara CSI/USB v√≠a **V4L2**.  
- **I2.** Red Ethernet/Wi-Fi para publicaci√≥n de m√©tricas/eventos.  
- **I3.** GPIO opcional (p.ej., LED indicador).  
- **D1.** **OpenCV** + **TensorFlow Lite**; **D2.** recetas Yocto; **D3.** servicio **systemd**.

### 3.4 Criterios de aceptaci√≥n
- **CA1.** RF/RNF documentados y **rastreables** a objetivos.
- **CA2.** Casos de uso demostrados **end-to-end** en Raspberry Pi.
- **CA3.** Diagrama **HW/SW** con funciones‚Üícomponentes e interfaces.
- **CA4.** **Build Yocto** reproducible con bit√°cora y √°rbol de dependencias.
- **CA5.** **Imagen bootea**, servicio corre, detecci√≥n visible y m√©tricas publicadas.
- **CA6.** **Plan** con hitos alineados a propuesta/demos.

---

## 4. Casos de uso

**Actores:** Operador (humano), C√°mara (sensor), Servicio de Detecci√≥n (app), Servicio de Publicaci√≥n (red), Sistema de Registro (logs).

- **UC1. Inicializar nodo** ‚Äî *Pre:* Imagen Yocto instalada. *Flujo:* Arranca SO ‚Üí systemd lanza app ‚Üí valida c√°mara/modelo. *Post:* Servicio ‚Äúlisto‚Äù.
- **UC2. Capturar video** ‚Äî *Flujo:* Obtener frames ‚â•10 FPS; manejar errores de dispositivo. *Post:* Frames en buffer.
- **UC3. Detectar y clasificar objetos** ‚Äî *Flujo:* Inferencia TFLite por frame ‚Üí bboxes + clase. *Post:* Detecciones por frame.
- **UC4. Seguir objetos (tracking)** ‚Äî *Flujo:* Asociar detecciones entre frames; asignar IDs; trayectorias. *Post:* Tracking activo.
- **UC5. Generar eventos y m√©tricas** ‚Äî *Flujo:* Conteos por clase/tiempo; KPIs. *Post:* Evento + KPIs actualizados.
- **UC6. Publicar datos a la red** ‚Äî *Flujo:* HTTP/MQTT; reconexi√≥n si falla. *Post:* Confirmaci√≥n o reintento.
- **UC7. Monitorear estado** ‚Äî *Flujo:* Consultar FPS/latencia/CPU/RAM/estado c√°mara-red. *Post:* Salud verificada.
- **UC8. Gestionar fallos de c√°mara** ‚Äî *Flujo:* Detectar desconexi√≥n; reabrir dispositivo; log. *Post:* Recuperaci√≥n sin reboot.
- **UC9. Apagar/actualizar nodo** ‚Äî *Flujo:* Detener servicio; actualizar imagen/paquete; reiniciar. *Post:* Nodo actualizado.
- **UC10. Demostraci√≥n acad√©mica** ‚Äî *Flujo:* Presentaci√≥n end-to-end en Pi. *Post:* Evidencia para evaluaci√≥n.

<p align="center">
  <img src="imagenes/Diagrama de caso de uso.png" alt="Casos de uso del sistema" width="600"/>
</p>

---

## 5. Arquitectura del sistema
> **TODO:** Diagrama HW/SW (Raspberry Pi, c√°mara, m√≥dulos ML, colas, red, logging, publicaci√≥n).  
> **TODO:** Describir componentes, interfaces (V4L2, HTTP/MQTT, systemd) y flujos de datos.
---

## 6. Vista operacional y funcional
> **TODO:** Escenarios de operaci√≥n, estados del nodo, flujos (captura‚Üídetecci√≥n‚Üítracking‚Üíeventos‚Üípublicaci√≥n), manejo de errores.
---

## 7. Plan de trabajo y cronograma
> **TODO:** Incluir Gantt y checklist de actividades/hitos hasta la demo.  
> **Hitos sugeridos:** Propuesta ‚Üí Arquitectura ‚Üí Recetas Yocto ‚Üí Imagen ‚Üí Pruebas en Pi ‚Üí Demo.
---

## 8. Integraci√≥n y despliegue (Yocto)

### 8.1 Requisitos de build
> **TODO:** Host, toolchain, caches (DL_DIR/SSTATE_DIR), ramas y versiones.
### 8.2 Capas y recetas
> **TODO:** meta, meta-poky, meta-yocto-bsp, meta-openembedded/meta-oe, capa propia (app + deps TFLite/OpenCV).
### 8.3 Servicio de la aplicaci√≥n (systemd)
> **TODO:** `*.service` con `Restart=always`, env vars, logs a journald/archivo.
### 8.4 Imagen y artefactos
> **TODO:** Tipo de imagen, tama√±o/particiones, m√©todo de flasheo, validaci√≥n post-flash.
---

## 9. Pruebas y validaci√≥n
- **Unitarias:** parsers, colas, post-proc.  
- **Integraci√≥n:** c√°mara‚Üídetecci√≥n‚Üíeventos‚Üípublicaci√≥n.  
- **Desempe√±o:** FPS, latencia.  
- **Robustez:** desconexi√≥n/reconexi√≥n de c√°mara, red intermitente.  
> **TODO:** Plan de pruebas con IDs (T-XXX), datos de prueba, criterios de pase/fallo y scripts.
---

## 10. M√©tricas y observabilidad
- **KPIs m√≠nimos:** FPS, latencia, CPU/RAM, tama√±o de cola, tasa de publicaci√≥n, conteos por clase.  
> **TODO:** Formato de logs (JSON/CSV), niveles, ejemplo de export (HTTP/MQTT), dashboard local si aplica.


---
## 14. üìö Documentaci√≥n Entrega Preliminar
- [Cronograma del proyecto](docs/CRONOGRAMA.md)
- [Informaci√≥n General del Sistema](docs/INFORMACION-GENERAL.md)
- [Informaci√≥n T√©cnica del Sistema](docs/INFORMACION-TECNICA.md)
- [Bit√°cora de Kendy](docs/BITACORA-KENDY.md)
- [Bit√°cora de Elena](docs/BITACORA-ELENA.md)
- [Bit√°cora de Chris](docs/BITACORA-CHRIS.md)

